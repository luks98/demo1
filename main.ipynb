{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from secrets import openai_api_key\n",
    "import openai\n",
    "import langchain\n",
    "import pinecone \n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "#from secrets import openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "    file_loader=PyPDFDirectoryLoader(directory)\n",
    "    documents=file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=read_doc(r'C:\\Users\\DebadattaNayak\\Desktop\\Langchain')\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents=chunk_data(docs=doc)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x00000137FAFDF710>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x00000137FB737690>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Embedding Technique Of OPENAI\n",
    "embeddings=OpenAIEmbeddings(api_key=\"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\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors=embeddings.embed_query(\"How are you?\")\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"f8afc0c0-0457-44e8-b3f7-241cd136b5c8\")\n",
    "index = pc.Index(\"langchainvector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create embeddings for each document chunk\n",
    "def create_embeddings(documents):\n",
    "    vector_data = []\n",
    "    for i, doc in enumerate(documents):\n",
    "        # Generate embeddings for the text chunk\n",
    "        vector = embeddings.embed_query(doc.page_content)\n",
    "        \n",
    "        # Prepare each vector entry for Pinecone\n",
    "        vector_entry = {\n",
    "            \"id\": f\"doc_{i}\",  # Unique identifier for each chunk\n",
    "            \"values\": vector,  # The embedded vector\n",
    "            \"metadata\": {\"text\": doc.page_content}  # Optional: Metadata about the chunk\n",
    "        }\n",
    "        vector_data.append(vector_entry)\n",
    "    return vector_data\n",
    "\n",
    "# Create vector data from document chunks\n",
    "vector_data = create_embeddings(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 141}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsert the vectors into the Pinecone index\n",
    "index.upsert(\n",
    "    vectors=vector_data,\n",
    "    namespace=\"budget2023\"  # Specify your namespace or use \"\" for default\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(openai_api_key=openai_api_key,temperature=0.8)\n",
    "\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_query = \"What is the benifits of this budget to public\"\n",
    "query_vectors = embeddings.embed_query(our_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'matches': [], 'namespace': 'ns1', 'usage': {'read_units': 5}}\n"
     ]
    }
   ],
   "source": [
    "matching_results=index.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=query_vectors,\n",
    "    top_k=2,\n",
    "    include_values=True,\n",
    "    include_metadata=True,\n",
    "    filter={\"genre\": {\"$eq\": \"finance\"}}\n",
    "\n",
    ")\n",
    "print(matching_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
